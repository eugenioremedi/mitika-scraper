name: Daily Mitika Scraper

on:
  schedule:
    - cron: "0 7 * * *"
  workflow_dispatch:

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install Python dependencies
        run: |
          pip install -r requirements.txt
          pip install google-api-python-client google-auth google-auth-oauthlib

      - name: Install Playwright browsers
        run: playwright install chromium

      - name: Run scraper
        run: python scraper.py
        env:
          MITIKA_USERNAME: ${{ secrets.MITIKA_USERNAME }}
          MITIKA_PASSWORD: ${{ secrets.MITIKA_PASSWORD }}

      - name: Upload to Google Drive
        run: |
          FILE_TO_UPLOAD=$(find output -name "BOOKINGS_*.xlsx" | head -n 1)
          if [ -z "$FILE_TO_UPLOAD" ]; then
            echo "No file found to upload!"
            exit 1
          fi
          echo "Found file: $FILE_TO_UPLOAD"
          python upload_to_drive.py "$FILE_TO_UPLOAD" "${{ secrets.GDRIVE_FOLDER_ID }}"
        env:
          GDRIVE_CLIENT_ID: ${{ secrets.GDRIVE_CLIENT_ID }}
          GDRIVE_CLIENT_SECRET: ${{ secrets.GDRIVE_CLIENT_SECRET }}
          GDRIVE_REFRESH_TOKEN: ${{ secrets.GDRIVE_REFRESH_TOKEN }}

      - name: Upload output (screenshots + files)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scraper-output
          path: output/
          retention-days: 7
